{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ucimlrepo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lk3WIoYuxRA",
        "outputId": "b1a8bf07-5c3c-41ee-c3b3-a8e73cc4588d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZbTfBLhucor",
        "outputId": "9962ebe3-5f29-4760-fdb3-7211d1fb85ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'uci_id': 967, 'name': 'PhiUSIIL Phishing URL (Website)', 'repository_url': 'https://archive.ics.uci.edu/dataset/967/phiusiil+phishing+url+dataset', 'data_url': 'https://archive.ics.uci.edu/static/public/967/data.csv', 'abstract': 'PhiUSIIL Phishing URL Dataset is a substantial dataset comprising 134,850 legitimate and 100,945 phishing URLs. Most of the URLs we analyzed, while constructing the dataset, are the latest URLs. Features are extracted from the source code of the webpage and URL. Features such as CharContinuationRate, URLTitleMatchScore, URLCharProb, and TLDLegitimateProb are derived from existing features.', 'area': 'Computer Science', 'tasks': ['Classification'], 'characteristics': ['Tabular'], 'num_instances': 235795, 'num_features': 54, 'feature_types': ['Real', 'Categorical', 'Integer'], 'demographics': [], 'target_col': ['label'], 'index_col': None, 'has_missing_values': 'no', 'missing_values_symbol': None, 'year_of_dataset_creation': 2024, 'last_updated': 'Sun May 12 2024', 'dataset_doi': 'https://doi.org/10.1016/j.cose.2023.103545', 'creators': ['Arvind Prasad', 'Shalini Chandra'], 'intro_paper': {'ID': 411, 'type': 'NATIVE', 'title': 'PhiUSIIL: A diverse security profile empowered phishing URL detection framework based on similarity index and incremental learning', 'authors': 'Arvind Prasad and Shalini Chandra', 'venue': 'Computers & Security', 'year': 2024, 'journal': None, 'DOI': None, 'URL': 'https://doi.org/10.1016/j.cose.2023.103545', 'sha': None, 'corpus': None, 'arxiv': None, 'mag': None, 'acl': None, 'pmid': None, 'pmcid': None}, 'additional_info': {'summary': None, 'purpose': None, 'funded_by': None, 'instances_represent': 'URLs and their corresponding webpages', 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': 'Column \"FILENAME\" can be ignored.', 'citation': 'Prasad, A., & Chandra, S. (2023). PhiUSIIL: A diverse security profile empowered phishing URL detection framework based on similarity index and incremental learning. Computers & Security, 103545. doi: https://doi.org/10.1016/j.cose.2023.103545'}}\n",
            "                          name     role         type demographic description  \\\n",
            "0                     FILENAME    Other  Categorical        None        None   \n",
            "1                          URL  Feature  Categorical        None        None   \n",
            "2                    URLLength  Feature      Integer        None        None   \n",
            "3                       Domain  Feature  Categorical        None        None   \n",
            "4                 DomainLength  Feature      Integer        None        None   \n",
            "5                   IsDomainIP  Feature      Integer        None        None   \n",
            "6                          TLD  Feature  Categorical        None        None   \n",
            "7           URLSimilarityIndex  Feature      Integer        None        None   \n",
            "8         CharContinuationRate  Feature      Integer        None        None   \n",
            "9            TLDLegitimateProb  Feature   Continuous        None        None   \n",
            "10                 URLCharProb  Feature   Continuous        None        None   \n",
            "11                   TLDLength  Feature      Integer        None        None   \n",
            "12               NoOfSubDomain  Feature      Integer        None        None   \n",
            "13              HasObfuscation  Feature      Integer        None        None   \n",
            "14          NoOfObfuscatedChar  Feature      Integer        None        None   \n",
            "15            ObfuscationRatio  Feature      Integer        None        None   \n",
            "16            NoOfLettersInURL  Feature      Integer        None        None   \n",
            "17            LetterRatioInURL  Feature   Continuous        None        None   \n",
            "18             NoOfDegitsInURL  Feature      Integer        None        None   \n",
            "19             DegitRatioInURL  Feature      Integer        None        None   \n",
            "20             NoOfEqualsInURL  Feature      Integer        None        None   \n",
            "21              NoOfQMarkInURL  Feature      Integer        None        None   \n",
            "22          NoOfAmpersandInURL  Feature      Integer        None        None   \n",
            "23  NoOfOtherSpecialCharsInURL  Feature      Integer        None        None   \n",
            "24       SpacialCharRatioInURL  Feature   Continuous        None        None   \n",
            "25                     IsHTTPS  Feature      Integer        None        None   \n",
            "26                  LineOfCode  Feature      Integer        None        None   \n",
            "27           LargestLineLength  Feature      Integer        None        None   \n",
            "28                    HasTitle  Feature      Integer        None        None   \n",
            "29                       Title  Feature  Categorical        None        None   \n",
            "30       DomainTitleMatchScore  Feature      Integer        None        None   \n",
            "31          URLTitleMatchScore  Feature      Integer        None        None   \n",
            "32                  HasFavicon  Feature      Integer        None        None   \n",
            "33                      Robots  Feature      Integer        None        None   \n",
            "34                IsResponsive  Feature      Integer        None        None   \n",
            "35             NoOfURLRedirect  Feature      Integer        None        None   \n",
            "36            NoOfSelfRedirect  Feature      Integer        None        None   \n",
            "37              HasDescription  Feature      Integer        None        None   \n",
            "38                   NoOfPopup  Feature      Integer        None        None   \n",
            "39                  NoOfiFrame  Feature      Integer        None        None   \n",
            "40       HasExternalFormSubmit  Feature      Integer        None        None   \n",
            "41                HasSocialNet  Feature      Integer        None        None   \n",
            "42             HasSubmitButton  Feature      Integer        None        None   \n",
            "43             HasHiddenFields  Feature      Integer        None        None   \n",
            "44            HasPasswordField  Feature      Integer        None        None   \n",
            "45                        Bank  Feature      Integer        None        None   \n",
            "46                         Pay  Feature      Integer        None        None   \n",
            "47                      Crypto  Feature      Integer        None        None   \n",
            "48            HasCopyrightInfo  Feature      Integer        None        None   \n",
            "49                   NoOfImage  Feature      Integer        None        None   \n",
            "50                     NoOfCSS  Feature      Integer        None        None   \n",
            "51                      NoOfJS  Feature      Integer        None        None   \n",
            "52                 NoOfSelfRef  Feature      Integer        None        None   \n",
            "53                NoOfEmptyRef  Feature      Integer        None        None   \n",
            "54             NoOfExternalRef  Feature      Integer        None        None   \n",
            "55                       label   Target      Integer        None        None   \n",
            "\n",
            "   units missing_values  \n",
            "0   None             no  \n",
            "1   None             no  \n",
            "2   None             no  \n",
            "3   None             no  \n",
            "4   None             no  \n",
            "5   None             no  \n",
            "6   None             no  \n",
            "7   None             no  \n",
            "8   None             no  \n",
            "9   None             no  \n",
            "10  None             no  \n",
            "11  None             no  \n",
            "12  None             no  \n",
            "13  None             no  \n",
            "14  None             no  \n",
            "15  None             no  \n",
            "16  None             no  \n",
            "17  None             no  \n",
            "18  None             no  \n",
            "19  None             no  \n",
            "20  None             no  \n",
            "21  None             no  \n",
            "22  None             no  \n",
            "23  None             no  \n",
            "24  None             no  \n",
            "25  None             no  \n",
            "26  None             no  \n",
            "27  None             no  \n",
            "28  None             no  \n",
            "29  None             no  \n",
            "30  None             no  \n",
            "31  None             no  \n",
            "32  None             no  \n",
            "33  None             no  \n",
            "34  None             no  \n",
            "35  None             no  \n",
            "36  None             no  \n",
            "37  None             no  \n",
            "38  None             no  \n",
            "39  None             no  \n",
            "40  None             no  \n",
            "41  None             no  \n",
            "42  None             no  \n",
            "43  None             no  \n",
            "44  None             no  \n",
            "45  None             no  \n",
            "46  None             no  \n",
            "47  None             no  \n",
            "48  None             no  \n",
            "49  None             no  \n",
            "50  None             no  \n",
            "51  None             no  \n",
            "52  None             no  \n",
            "53  None             no  \n",
            "54  None             no  \n",
            "55  None             no  \n"
          ]
        }
      ],
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "# fetch dataset\n",
        "phiusiil_phishing_url_website = fetch_ucirepo(id=967)\n",
        "\n",
        "# data (as pandas dataframes)\n",
        "X = phiusiil_phishing_url_website.data.features\n",
        "y = phiusiil_phishing_url_website.data.targets\n",
        "\n",
        "# metadata\n",
        "print(phiusiil_phishing_url_website.metadata)\n",
        "\n",
        "# variable information\n",
        "print(phiusiil_phishing_url_website.variables)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.preprocessing import Binarizer\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Fetch PhiUSIIL Phishing URL dataset\n",
        "phiusiil_phishing_url_website = fetch_ucirepo(id=967)\n",
        "\n",
        "# 2. Load data\n",
        "X = phiusiil_phishing_url_website.data.features\n",
        "y = phiusiil_phishing_url_website.data.targets\n",
        "\n",
        "# If 'y' is a DataFrame with one column, convert to Series\n",
        "if isinstance(y, pd.DataFrame):\n",
        "    y = y.iloc[:, 0]\n",
        "\n",
        "# 3. Optional: Explore metadata\n",
        "#print(phiusiil_phishing_url_website.metadata)\n",
        "#print(phiusiil_phishing_url_website.variables)\n",
        "\n",
        "# 4. Drop non-numeric columns before binarizing\n",
        "X_numeric = X.select_dtypes(include=['number'])\n",
        "\n",
        "# 5. Binarize for BernoulliNB\n",
        "binarizer = Binarizer()\n",
        "X_bin = binarizer.fit_transform(X_numeric)\n",
        "\n",
        "# 6. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_bin, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 7. Train Bernoulli Naive Bayes model\n",
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train, y_train)\n",
        "\n",
        "# 8. Make predictions\n",
        "y_pred = bnb.predict(X_test)\n",
        "\n",
        "# 9. Evaluation\n",
        "print(\"ðŸ”¹ Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nðŸ”¹ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"ðŸ”¹ Accuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUUN9VECu8v-",
        "outputId": "f9fa2aae-a6b6-48b3-82e4-3131a885b8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”¹ Confusion Matrix:\n",
            "[[29278   873]\n",
            " [   77 40511]]\n",
            "\n",
            "ðŸ”¹ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.97      0.98     30151\n",
            "           1       0.98      1.00      0.99     40588\n",
            "\n",
            "    accuracy                           0.99     70739\n",
            "   macro avg       0.99      0.98      0.99     70739\n",
            "weighted avg       0.99      0.99      0.99     70739\n",
            "\n",
            "ðŸ”¹ Accuracy Score: 0.986570350160449\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "import unicodedata\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from difflib import SequenceMatcher\n",
        "\n",
        "# Step 1: Fetch dataset\n",
        "phiusiil = fetch_ucirepo(id=967)\n",
        "X_raw = phiusiil.data.features\n",
        "y = phiusiil.data.targets.iloc[:, 0] if isinstance(phiusiil.data.targets, pd.DataFrame) else phiusiil.data.targets\n",
        "\n",
        "# Step 2: Feature Engineering from URL\n",
        "def extract_features(url):\n",
        "    parsed = urlparse(url)\n",
        "    hostname = parsed.netloc.lower()\n",
        "    path = parsed.path.lower()\n",
        "    full = url.lower()\n",
        "\n",
        "    def looks_like(target, url):\n",
        "        return SequenceMatcher(None, target, url).ratio()\n",
        "\n",
        "    features = {\n",
        "        'url_length': len(full),\n",
        "        'has_https': int(parsed.scheme == 'https'),\n",
        "        'num_dots': full.count('.'),\n",
        "        'num_hyphens': full.count('-'),\n",
        "        'num_slashes': full.count('/'),\n",
        "        'num_digits': sum(c.isdigit() for c in full),\n",
        "        'has_ip': int(any(char.isdigit() for char in hostname.split('.')[0])),\n",
        "        'homograph_google': looks_like('google.com', hostname),\n",
        "        'homograph_paypal': looks_like('paypal.com', hostname),\n",
        "        'homograph_amazon': looks_like('amazon.com', hostname)\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Apply to dataset\n",
        "X = pd.DataFrame([extract_features(url) for url in X_raw['URL']])\n",
        "\n",
        "# Step 3: Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 4: Incremental Learning\n",
        "scaler = StandardScaler()\n",
        "clf = SGDClassifier(loss='log_loss', max_iter=1000)\n",
        "\n",
        "X_train_batches = np.array_split(X_train, 10)\n",
        "y_train_batches = np.array_split(y_train, 10)\n",
        "\n",
        "# Scale first batch and fit\n",
        "X0 = scaler.fit_transform(X_train_batches[0])\n",
        "clf.partial_fit(X0, y_train_batches[0], classes=np.unique(y_train))\n",
        "\n",
        "# Incremental updates\n",
        "for i in range(1, len(X_train_batches)):\n",
        "    Xi = scaler.transform(X_train_batches[i])\n",
        "    clf.partial_fit(Xi, y_train_batches[i])\n",
        "\n",
        "# Final Evaluation\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "# Results\n",
        "print(\"\\nðŸ”¹ Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\nðŸ”¹ Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\nðŸ”¹ Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrXCZgJDyFbm",
        "outputId": "87996030-da6f-41a7-d5f9-db9ab0198e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ Confusion Matrix:\n",
            "[[19837   287]\n",
            " [    7 27028]]\n",
            "\n",
            "ðŸ”¹ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      0.99     20124\n",
            "           1       0.99      1.00      0.99     27035\n",
            "\n",
            "    accuracy                           0.99     47159\n",
            "   macro avg       0.99      0.99      0.99     47159\n",
            "weighted avg       0.99      0.99      0.99     47159\n",
            "\n",
            "\n",
            "ðŸ”¹ Accuracy Score: 0.9937657711147395\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
            "  return bound(*args, **kwds)\n",
            "/usr/local/lib/python3.11/dist-packages/numpy/_core/fromnumeric.py:57: FutureWarning: 'Series.swapaxes' is deprecated and will be removed in a future version. Please use 'Series.transpose' instead.\n",
            "  return bound(*args, **kwds)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse\n",
        "import unicodedata\n",
        "from difflib import SequenceMatcher\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# Step 1: Fetch dataset\n",
        "phiusiil = fetch_ucirepo(id=967)\n",
        "X_raw = phiusiil.data.features\n",
        "y = phiusiil.data.targets.iloc[:, 0] if isinstance(phiusiil.data.targets, pd.DataFrame) else phiusiil.data.targets\n",
        "\n",
        "# Step 2: Similarity & Feature Functions\n",
        "def looks_like(target, url):\n",
        "    return SequenceMatcher(None, target, url).ratio()\n",
        "\n",
        "def contains_zero_width(url):\n",
        "    return any(c in url for c in ['\\u200b', '\\u200c', '\\u200d'])\n",
        "\n",
        "def is_punycode(url):\n",
        "    return 'xn--' in urlparse(url).netloc\n",
        "\n",
        "def extract_features(url):\n",
        "    parsed = urlparse(url)\n",
        "    hostname = parsed.netloc.lower()\n",
        "    path = parsed.path.lower()\n",
        "    full = url.lower()\n",
        "\n",
        "    features = {\n",
        "        'url_length': len(full),\n",
        "        'has_https': int(parsed.scheme == 'https'),\n",
        "        'num_dots': full.count('.'),\n",
        "        'num_hyphens': full.count('-'),\n",
        "        'num_slashes': full.count('/'),\n",
        "        'num_digits': sum(c.isdigit() for c in full),\n",
        "        'has_ip': int(any(char.isdigit() for char in hostname.split('.')[0])),\n",
        "        'homograph_google': looks_like('google.com', hostname),\n",
        "        'homograph_paypal': looks_like('paypal.com', hostname),\n",
        "        'homograph_amazon': looks_like('amazon.com', hostname),\n",
        "        'has_zero_width': int(contains_zero_width(full)),\n",
        "        'is_punycode': int(is_punycode(url)),\n",
        "        'homograph_combined': max(\n",
        "            looks_like('google.com', hostname),\n",
        "            looks_like('paypal.com', hostname),\n",
        "            looks_like('amazon.com', hostname)\n",
        "        )\n",
        "    }\n",
        "    return features\n",
        "\n",
        "# Step 3: Extract Features\n",
        "X = pd.DataFrame([extract_features(url) for url in X_raw['URL']])\n",
        "\n",
        "# Step 4: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 5: Model Training with XGBoost\n",
        "clf = XGBClassifier(n_estimators=100, max_depth=6, learning_rate=0.1, use_label_encoder=False, eval_metric='logloss')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Step 6: Predictions and Evaluation\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "print(\"\\n\\U0001F4D9 Confusion Matrix:\")\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(\"\\n\\U0001F4D9 Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "print(\"\\n\\U0001F4D9 Accuracy Score:\", accuracy_score(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_lxPSm7yFvn",
        "outputId": "a7b6bc55-6f6e-4d32-e5eb-8126c52fa091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [09:23:16] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ“™ Confusion Matrix:\n",
            "[[19947   177]\n",
            " [   11 27024]]\n",
            "\n",
            "ðŸ“™ Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.99      1.00     20124\n",
            "           1       0.99      1.00      1.00     27035\n",
            "\n",
            "    accuracy                           1.00     47159\n",
            "   macro avg       1.00      1.00      1.00     47159\n",
            "weighted avg       1.00      1.00      1.00     47159\n",
            "\n",
            "\n",
            "ðŸ“™ Accuracy Score: 0.9960134862910579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "AGxWKciF4iXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Assuming 'clf' is your trained model\n",
        "model_filename = 'xgb_phishing_model.pkl'\n",
        "with open(model_filename, 'wb') as f:\n",
        "    pickle.dump(clf, f)\n"
      ],
      "metadata": {
        "id": "OSAfSQoD4lpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TIHV1hJH57VG"
      },
      "execution_count": 26,
      "outputs": []
    }
  ]
}